{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test) = fashion_mnist.load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ndim(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b56396f808>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train/255\n",
    "X_test=X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00392157, 0.        , 0.        ,\n",
       "        0.05098039, 0.28627451, 0.        , 0.        , 0.00392157,\n",
       "        0.01568627, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00392157, 0.00392157, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.        , 0.14117647,\n",
       "        0.53333333, 0.49803922, 0.24313725, 0.21176471, 0.        ,\n",
       "        0.        , 0.        , 0.00392157, 0.01176471, 0.01568627,\n",
       "        0.        , 0.        , 0.01176471],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.02352941, 0.        , 0.4       ,\n",
       "        0.8       , 0.69019608, 0.5254902 , 0.56470588, 0.48235294,\n",
       "        0.09019608, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.04705882, 0.03921569, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.60784314,\n",
       "        0.9254902 , 0.81176471, 0.69803922, 0.41960784, 0.61176471,\n",
       "        0.63137255, 0.42745098, 0.25098039, 0.09019608, 0.30196078,\n",
       "        0.50980392, 0.28235294, 0.05882353],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00392157, 0.        , 0.27058824, 0.81176471,\n",
       "        0.8745098 , 0.85490196, 0.84705882, 0.84705882, 0.63921569,\n",
       "        0.49803922, 0.4745098 , 0.47843137, 0.57254902, 0.55294118,\n",
       "        0.34509804, 0.6745098 , 0.25882353],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.00392157, 0.00392157, 0.        , 0.78431373, 0.90980392,\n",
       "        0.90980392, 0.91372549, 0.89803922, 0.8745098 , 0.8745098 ,\n",
       "        0.84313725, 0.83529412, 0.64313725, 0.49803922, 0.48235294,\n",
       "        0.76862745, 0.89803922, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.71764706, 0.88235294,\n",
       "        0.84705882, 0.8745098 , 0.89411765, 0.92156863, 0.89019608,\n",
       "        0.87843137, 0.87058824, 0.87843137, 0.86666667, 0.8745098 ,\n",
       "        0.96078431, 0.67843137, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.75686275, 0.89411765,\n",
       "        0.85490196, 0.83529412, 0.77647059, 0.70588235, 0.83137255,\n",
       "        0.82352941, 0.82745098, 0.83529412, 0.8745098 , 0.8627451 ,\n",
       "        0.95294118, 0.79215686, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.01176471, 0.        , 0.04705882, 0.85882353, 0.8627451 ,\n",
       "        0.83137255, 0.85490196, 0.75294118, 0.6627451 , 0.89019608,\n",
       "        0.81568627, 0.85490196, 0.87843137, 0.83137255, 0.88627451,\n",
       "        0.77254902, 0.81960784, 0.20392157],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02352941, 0.        , 0.38823529, 0.95686275, 0.87058824,\n",
       "        0.8627451 , 0.85490196, 0.79607843, 0.77647059, 0.86666667,\n",
       "        0.84313725, 0.83529412, 0.87058824, 0.8627451 , 0.96078431,\n",
       "        0.46666667, 0.65490196, 0.21960784],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01568627,\n",
       "        0.        , 0.        , 0.21568627, 0.9254902 , 0.89411765,\n",
       "        0.90196078, 0.89411765, 0.94117647, 0.90980392, 0.83529412,\n",
       "        0.85490196, 0.8745098 , 0.91764706, 0.85098039, 0.85098039,\n",
       "        0.81960784, 0.36078431, 0.        ],\n",
       "       [0.        , 0.        , 0.00392157, 0.01568627, 0.02352941,\n",
       "        0.02745098, 0.00784314, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.92941176, 0.88627451, 0.85098039,\n",
       "        0.8745098 , 0.87058824, 0.85882353, 0.87058824, 0.86666667,\n",
       "        0.84705882, 0.8745098 , 0.89803922, 0.84313725, 0.85490196,\n",
       "        1.        , 0.30196078, 0.        ],\n",
       "       [0.        , 0.01176471, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.24313725,\n",
       "        0.56862745, 0.8       , 0.89411765, 0.81176471, 0.83529412,\n",
       "        0.86666667, 0.85490196, 0.81568627, 0.82745098, 0.85490196,\n",
       "        0.87843137, 0.8745098 , 0.85882353, 0.84313725, 0.87843137,\n",
       "        0.95686275, 0.62352941, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.07058824,\n",
       "        0.17254902, 0.32156863, 0.41960784, 0.74117647, 0.89411765,\n",
       "        0.8627451 , 0.87058824, 0.85098039, 0.88627451, 0.78431373,\n",
       "        0.80392157, 0.82745098, 0.90196078, 0.87843137, 0.91764706,\n",
       "        0.69019608, 0.7372549 , 0.98039216, 0.97254902, 0.91372549,\n",
       "        0.93333333, 0.84313725, 0.        ],\n",
       "       [0.        , 0.22352941, 0.73333333, 0.81568627, 0.87843137,\n",
       "        0.86666667, 0.87843137, 0.81568627, 0.8       , 0.83921569,\n",
       "        0.81568627, 0.81960784, 0.78431373, 0.62352941, 0.96078431,\n",
       "        0.75686275, 0.80784314, 0.8745098 , 1.        , 1.        ,\n",
       "        0.86666667, 0.91764706, 0.86666667, 0.82745098, 0.8627451 ,\n",
       "        0.90980392, 0.96470588, 0.        ],\n",
       "       [0.01176471, 0.79215686, 0.89411765, 0.87843137, 0.86666667,\n",
       "        0.82745098, 0.82745098, 0.83921569, 0.80392157, 0.80392157,\n",
       "        0.80392157, 0.8627451 , 0.94117647, 0.31372549, 0.58823529,\n",
       "        1.        , 0.89803922, 0.86666667, 0.7372549 , 0.60392157,\n",
       "        0.74901961, 0.82352941, 0.8       , 0.81960784, 0.87058824,\n",
       "        0.89411765, 0.88235294, 0.        ],\n",
       "       [0.38431373, 0.91372549, 0.77647059, 0.82352941, 0.87058824,\n",
       "        0.89803922, 0.89803922, 0.91764706, 0.97647059, 0.8627451 ,\n",
       "        0.76078431, 0.84313725, 0.85098039, 0.94509804, 0.25490196,\n",
       "        0.28627451, 0.41568627, 0.45882353, 0.65882353, 0.85882353,\n",
       "        0.86666667, 0.84313725, 0.85098039, 0.8745098 , 0.8745098 ,\n",
       "        0.87843137, 0.89803922, 0.11372549],\n",
       "       [0.29411765, 0.8       , 0.83137255, 0.8       , 0.75686275,\n",
       "        0.80392157, 0.82745098, 0.88235294, 0.84705882, 0.7254902 ,\n",
       "        0.77254902, 0.80784314, 0.77647059, 0.83529412, 0.94117647,\n",
       "        0.76470588, 0.89019608, 0.96078431, 0.9372549 , 0.8745098 ,\n",
       "        0.85490196, 0.83137255, 0.81960784, 0.87058824, 0.8627451 ,\n",
       "        0.86666667, 0.90196078, 0.2627451 ],\n",
       "       [0.18823529, 0.79607843, 0.71764706, 0.76078431, 0.83529412,\n",
       "        0.77254902, 0.7254902 , 0.74509804, 0.76078431, 0.75294118,\n",
       "        0.79215686, 0.83921569, 0.85882353, 0.86666667, 0.8627451 ,\n",
       "        0.9254902 , 0.88235294, 0.84705882, 0.78039216, 0.80784314,\n",
       "        0.72941176, 0.70980392, 0.69411765, 0.6745098 , 0.70980392,\n",
       "        0.80392157, 0.80784314, 0.45098039],\n",
       "       [0.        , 0.47843137, 0.85882353, 0.75686275, 0.70196078,\n",
       "        0.67058824, 0.71764706, 0.76862745, 0.8       , 0.82352941,\n",
       "        0.83529412, 0.81176471, 0.82745098, 0.82352941, 0.78431373,\n",
       "        0.76862745, 0.76078431, 0.74901961, 0.76470588, 0.74901961,\n",
       "        0.77647059, 0.75294118, 0.69019608, 0.61176471, 0.65490196,\n",
       "        0.69411765, 0.82352941, 0.36078431],\n",
       "       [0.        , 0.        , 0.29019608, 0.74117647, 0.83137255,\n",
       "        0.74901961, 0.68627451, 0.6745098 , 0.68627451, 0.70980392,\n",
       "        0.7254902 , 0.7372549 , 0.74117647, 0.7372549 , 0.75686275,\n",
       "        0.77647059, 0.8       , 0.81960784, 0.82352941, 0.82352941,\n",
       "        0.82745098, 0.7372549 , 0.7372549 , 0.76078431, 0.75294118,\n",
       "        0.84705882, 0.66666667, 0.        ],\n",
       "       [0.00784314, 0.        , 0.        , 0.        , 0.25882353,\n",
       "        0.78431373, 0.87058824, 0.92941176, 0.9372549 , 0.94901961,\n",
       "        0.96470588, 0.95294118, 0.95686275, 0.86666667, 0.8627451 ,\n",
       "        0.75686275, 0.74901961, 0.70196078, 0.71372549, 0.71372549,\n",
       "        0.70980392, 0.69019608, 0.65098039, 0.65882353, 0.38823529,\n",
       "        0.22745098, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15686275, 0.23921569, 0.17254902,\n",
       "        0.28235294, 0.16078431, 0.1372549 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,Flatten,MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chirag M. Sidhdhapur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1..., activation=\"relu\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model.add(Conv2D(32,3,3,input_shape=(28,28,1),activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(20,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reshaped = X_train.reshape(-1,28, 28, 1)   #Reshape for CNN -  should work!!\n",
    "X_test_reshaped = X_test.reshape(-1,28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 15s 313us/step - loss: 0.5824 - acc: 0.7971 - val_loss: 0.4080 - val_acc: 0.8558\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 15s 304us/step - loss: 0.3707 - acc: 0.8721 - val_loss: 0.3398 - val_acc: 0.8802\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 15s 303us/step - loss: 0.3185 - acc: 0.8893 - val_loss: 0.3159 - val_acc: 0.8911\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 15s 302us/step - loss: 0.2878 - acc: 0.8988 - val_loss: 0.2979 - val_acc: 0.8942\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 15s 304us/step - loss: 0.2662 - acc: 0.9062 - val_loss: 0.2847 - val_acc: 0.8986\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 15s 304us/step - loss: 0.2470 - acc: 0.9132 - val_loss: 0.2780 - val_acc: 0.9017\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 15s 309us/step - loss: 0.2314 - acc: 0.9170 - val_loss: 0.2729 - val_acc: 0.9018\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 15s 306us/step - loss: 0.2167 - acc: 0.9225 - val_loss: 0.2650 - val_acc: 0.9057\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 15s 306us/step - loss: 0.2042 - acc: 0.9273 - val_loss: 0.2622 - val_acc: 0.9067\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 15s 310us/step - loss: 0.1909 - acc: 0.9312 - val_loss: 0.2684 - val_acc: 0.9074\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 15s 309us/step - loss: 0.1804 - acc: 0.9349 - val_loss: 0.2653 - val_acc: 0.9077\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 15s 309us/step - loss: 0.1694 - acc: 0.9401 - val_loss: 0.2717 - val_acc: 0.9073\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 15s 309us/step - loss: 0.1608 - acc: 0.9422 - val_loss: 0.2750 - val_acc: 0.9065\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 15s 316us/step - loss: 0.1508 - acc: 0.9464 - val_loss: 0.2727 - val_acc: 0.9084\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 15s 308us/step - loss: 0.1437 - acc: 0.9491 - val_loss: 0.2762 - val_acc: 0.9110\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 15s 310us/step - loss: 0.1366 - acc: 0.9507 - val_loss: 0.3008 - val_acc: 0.9034\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 15s 311us/step - loss: 0.1307 - acc: 0.9536 - val_loss: 0.3091 - val_acc: 0.9050\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 15s 312us/step - loss: 0.1236 - acc: 0.9566 - val_loss: 0.3030 - val_acc: 0.9067\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 15s 313us/step - loss: 0.1171 - acc: 0.9586 - val_loss: 0.3015 - val_acc: 0.9074\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 15s 313us/step - loss: 0.1124 - acc: 0.9604 - val_loss: 0.3041 - val_acc: 0.9126\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 15s 316us/step - loss: 0.1080 - acc: 0.9620 - val_loss: 0.3251 - val_acc: 0.9046\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 15s 314us/step - loss: 0.1019 - acc: 0.9641 - val_loss: 0.3283 - val_acc: 0.9051\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 15s 316us/step - loss: 0.0991 - acc: 0.9646 - val_loss: 0.3254 - val_acc: 0.9106\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 15s 316us/step - loss: 0.0959 - acc: 0.9659 - val_loss: 0.3502 - val_acc: 0.9081\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 15s 317us/step - loss: 0.0915 - acc: 0.9681 - val_loss: 0.3381 - val_acc: 0.9083\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 15s 318us/step - loss: 0.0880 - acc: 0.9681 - val_loss: 0.3656 - val_acc: 0.9011\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 15s 320us/step - loss: 0.0837 - acc: 0.9698 - val_loss: 0.3649 - val_acc: 0.9054\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 15s 311us/step - loss: 0.0807 - acc: 0.9718 - val_loss: 0.3713 - val_acc: 0.9021\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 15s 309us/step - loss: 0.0787 - acc: 0.9717 - val_loss: 0.4019 - val_acc: 0.9018\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 15s 313us/step - loss: 0.0746 - acc: 0.9732 - val_loss: 0.3819 - val_acc: 0.9058\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 15s 311us/step - loss: 0.0730 - acc: 0.9746 - val_loss: 0.3929 - val_acc: 0.9054\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 15s 310us/step - loss: 0.0684 - acc: 0.9753 - val_loss: 0.3983 - val_acc: 0.9020\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 15s 321us/step - loss: 0.0667 - acc: 0.9763 - val_loss: 0.4071 - val_acc: 0.9068\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 15s 315us/step - loss: 0.0654 - acc: 0.9766 - val_loss: 0.4221 - val_acc: 0.9026\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 15s 316us/step - loss: 0.0628 - acc: 0.9783 - val_loss: 0.4297 - val_acc: 0.9019\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 15s 315us/step - loss: 0.0587 - acc: 0.9792 - val_loss: 0.4253 - val_acc: 0.9062\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 15s 307us/step - loss: 0.0566 - acc: 0.9804 - val_loss: 0.4478 - val_acc: 0.9042\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 319s 7ms/step - loss: 0.0546 - acc: 0.9815 - val_loss: 0.4707 - val_acc: 0.8992\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 16s 332us/step - loss: 0.0570 - acc: 0.9799 - val_loss: 0.4580 - val_acc: 0.9016\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 15s 323us/step - loss: 0.0505 - acc: 0.9830 - val_loss: 0.4792 - val_acc: 0.9040\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 16s 331us/step - loss: 0.0497 - acc: 0.9831 - val_loss: 0.4927 - val_acc: 0.9048\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 16s 338us/step - loss: 0.0479 - acc: 0.9830 - val_loss: 0.4868 - val_acc: 0.9043\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 16s 338us/step - loss: 0.0478 - acc: 0.9828 - val_loss: 0.4990 - val_acc: 0.9044\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 15s 322us/step - loss: 0.0449 - acc: 0.9840 - val_loss: 0.5176 - val_acc: 0.9038\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 16s 337us/step - loss: 0.0450 - acc: 0.9837 - val_loss: 0.5290 - val_acc: 0.9015\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 16s 328us/step - loss: 0.0437 - acc: 0.9848 - val_loss: 0.5305 - val_acc: 0.9002\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 15s 315us/step - loss: 0.0418 - acc: 0.9858 - val_loss: 0.5266 - val_acc: 0.9032\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 16s 334us/step - loss: 0.0399 - acc: 0.9865 - val_loss: 0.5483 - val_acc: 0.8968\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 16s 326us/step - loss: 0.0408 - acc: 0.9859 - val_loss: 0.5858 - val_acc: 0.8902\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 16s 325us/step - loss: 0.0396 - acc: 0.9858 - val_loss: 0.5478 - val_acc: 0.9028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b563a91a88>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_reshaped,y_train,batch_size=32,epochs=50,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 77us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7000137441627681, 0.8901]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_reshaped,y_test)\n",
    "[0.7000137441627681, 0.8901]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.9986924e-14, 1.1598973e-18, 1.5508441e-07, 6.4510498e-19,\n",
       "       2.1910817e-15, 4.3969902e-07, 9.6963995e-13, 1.1084234e-06,\n",
       "       3.0651763e-09, 9.9999833e-01], dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-12c64b2fa888>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mmatshow\u001b[1;34m(A, fignum, **kwargs)\u001b[0m\n\u001b[0;32m   2186\u001b[0m         \u001b[1;31m# Extract actual aspect ratio of array and make appropriately sized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2187\u001b[0m         \u001b[1;31m# figure.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2188\u001b[1;33m         \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfignum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfigaspect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2189\u001b[0m         \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_axes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.09\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.775\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.775\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2190\u001b[0m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36mfigaspect\u001b[1;34m(arg)\u001b[0m\n\u001b[0;32m   2741\u001b[0m     \u001b[1;31m# Extract the aspect ratio of the array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2742\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2743\u001b[1;33m         \u001b[0mnr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2744\u001b[0m         \u001b[0marr_ratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnr\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2745\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "plt.matshow(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
