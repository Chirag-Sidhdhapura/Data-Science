{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V9E-fLrPyjE-"
   },
   "outputs": [],
   "source": [
    "#import pandas and numpy\n",
    "import pandas as pd \n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking any random paragraph as our data and will train model to predict next word in it \n",
    "\n",
    "data=\"\"\"A lion was once sleeping in the jungle when a mouse started running up and down his body just for fun. This disturbed the lion’s sleep, and he woke up quite angry. He was about to eat the mouse when the mouse desperately requested the lion to set him free. “I promise you, I will be of great help to you someday if you save me.” The lion laughed at the mouse’s confidence and let him go.\n",
    "\n",
    "One day, a few hunters came into the forest and took the lion with them. They tied him up against a tree. The lion was struggling to get out and started to whimper. Soon, the mouse walked past and noticed the lion in trouble. Quickly, he ran and gnawed on the ropes to set the lion free. Both of them sped off into the jungle.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk for working with text data \n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate each sentence in paragrath\n",
    "sentences=nltk.sent_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert text into sequences of numbers\n",
    "encoded=tokenizer.texts_to_sequences([data])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 2,\n",
       " 7,\n",
       " 21,\n",
       " 22,\n",
       " 12,\n",
       " 1,\n",
       " 13,\n",
       " 14,\n",
       " 5,\n",
       " 6,\n",
       " 15,\n",
       " 23,\n",
       " 8,\n",
       " 3,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 1,\n",
       " 32,\n",
       " 33,\n",
       " 3,\n",
       " 9,\n",
       " 34,\n",
       " 8,\n",
       " 35,\n",
       " 36,\n",
       " 9,\n",
       " 7,\n",
       " 37,\n",
       " 4,\n",
       " 38,\n",
       " 1,\n",
       " 6,\n",
       " 14,\n",
       " 1,\n",
       " 6,\n",
       " 39,\n",
       " 40,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 16,\n",
       " 10,\n",
       " 17,\n",
       " 41,\n",
       " 42,\n",
       " 11,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 18,\n",
       " 46,\n",
       " 47,\n",
       " 4,\n",
       " 11,\n",
       " 48,\n",
       " 49,\n",
       " 11,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 1,\n",
       " 2,\n",
       " 53,\n",
       " 54,\n",
       " 1,\n",
       " 55,\n",
       " 56,\n",
       " 3,\n",
       " 57,\n",
       " 10,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 5,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 19,\n",
       " 1,\n",
       " 64,\n",
       " 3,\n",
       " 65,\n",
       " 1,\n",
       " 2,\n",
       " 66,\n",
       " 20,\n",
       " 67,\n",
       " 68,\n",
       " 10,\n",
       " 8,\n",
       " 69,\n",
       " 5,\n",
       " 70,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 71,\n",
       " 4,\n",
       " 72,\n",
       " 73,\n",
       " 3,\n",
       " 15,\n",
       " 4,\n",
       " 74,\n",
       " 75,\n",
       " 1,\n",
       " 6,\n",
       " 76,\n",
       " 77,\n",
       " 3,\n",
       " 78,\n",
       " 1,\n",
       " 2,\n",
       " 12,\n",
       " 79,\n",
       " 80,\n",
       " 9,\n",
       " 81,\n",
       " 3,\n",
       " 82,\n",
       " 83,\n",
       " 1,\n",
       " 84,\n",
       " 4,\n",
       " 16,\n",
       " 1,\n",
       " 2,\n",
       " 17,\n",
       " 85,\n",
       " 18,\n",
       " 20,\n",
       " 86,\n",
       " 87,\n",
       " 19,\n",
       " 1,\n",
       " 13]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s58euH1-yDai"
   },
   "outputs": [],
   "source": [
    "#define total vocabulary size\n",
    "vocab_size=len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create seperate lists of 4 sequences since we will use three of them as input and last one as output\n",
    "sequences=[]\n",
    "for i in range(len(encoded)-3):\n",
    "    sequences.append(encoded[i:i+4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 20, 29, 47],\n",
       " [20, 29, 47, 48],\n",
       " [29, 47, 48, 36],\n",
       " [47, 48, 36, 14],\n",
       " [48, 36, 14, 37],\n",
       " [36, 14, 37, 38],\n",
       " [14, 37, 38, 5],\n",
       " [37, 38, 5, 26],\n",
       " [38, 5, 26, 39],\n",
       " [5, 26, 39, 49],\n",
       " [26, 39, 49, 30],\n",
       " [39, 49, 30, 21],\n",
       " [49, 30, 21, 50],\n",
       " [30, 21, 50, 51],\n",
       " [21, 50, 51, 52],\n",
       " [50, 51, 52, 53],\n",
       " [51, 52, 53, 54],\n",
       " [52, 53, 54, 55],\n",
       " [53, 54, 55, 56],\n",
       " [54, 55, 56, 57],\n",
       " [55, 56, 57, 14],\n",
       " [56, 57, 14, 58],\n",
       " [57, 14, 58, 59],\n",
       " [14, 58, 59, 21],\n",
       " [58, 59, 21, 31],\n",
       " [59, 21, 31, 60],\n",
       " [21, 31, 60, 30],\n",
       " [31, 60, 30, 61],\n",
       " [60, 30, 61, 62],\n",
       " [30, 61, 62, 31],\n",
       " [61, 62, 31, 29],\n",
       " [62, 31, 29, 63],\n",
       " [31, 29, 63, 24],\n",
       " [29, 63, 24, 64],\n",
       " [63, 24, 64, 14],\n",
       " [24, 64, 14, 26],\n",
       " [64, 14, 26, 38],\n",
       " [14, 26, 38, 14],\n",
       " [26, 38, 14, 26],\n",
       " [38, 14, 26, 65],\n",
       " [14, 26, 65, 66],\n",
       " [26, 65, 66, 14],\n",
       " [65, 66, 14, 20],\n",
       " [66, 14, 20, 24],\n",
       " [14, 20, 24, 40],\n",
       " [20, 24, 40, 32],\n",
       " [24, 40, 32, 41],\n",
       " [40, 32, 41, 67],\n",
       " [32, 41, 67, 68],\n",
       " [41, 67, 68, 33],\n",
       " [67, 68, 33, 6],\n",
       " [68, 33, 6, 69],\n",
       " [33, 6, 69, 70],\n",
       " [6, 69, 70, 42],\n",
       " [69, 70, 42, 71],\n",
       " [70, 42, 71, 72],\n",
       " [42, 71, 72, 24],\n",
       " [71, 72, 24, 33],\n",
       " [72, 24, 33, 73],\n",
       " [24, 33, 73, 74],\n",
       " [33, 73, 74, 33],\n",
       " [73, 74, 33, 75],\n",
       " [74, 33, 75, 76],\n",
       " [33, 75, 76, 35],\n",
       " [75, 76, 35, 14],\n",
       " [76, 35, 14, 20],\n",
       " [35, 14, 20, 77],\n",
       " [14, 20, 77, 78],\n",
       " [20, 77, 78, 14],\n",
       " [77, 78, 14, 79],\n",
       " [78, 14, 79, 80],\n",
       " [14, 79, 80, 21],\n",
       " [79, 80, 21, 81],\n",
       " [80, 21, 81, 32],\n",
       " [21, 81, 32, 82],\n",
       " [81, 32, 82, 83],\n",
       " [32, 82, 83, 84],\n",
       " [82, 83, 84, 5],\n",
       " [83, 84, 5, 85],\n",
       " [84, 5, 85, 86],\n",
       " [5, 85, 86, 87],\n",
       " [85, 86, 87, 43],\n",
       " [86, 87, 43, 14],\n",
       " [87, 43, 14, 88],\n",
       " [43, 14, 88, 21],\n",
       " [14, 88, 21, 89],\n",
       " [88, 21, 89, 14],\n",
       " [21, 89, 14, 20],\n",
       " [89, 14, 20, 90],\n",
       " [14, 20, 90, 44],\n",
       " [20, 90, 44, 91],\n",
       " [90, 44, 91, 92],\n",
       " [44, 91, 92, 32],\n",
       " [91, 92, 32, 30],\n",
       " [92, 32, 30, 93],\n",
       " [32, 30, 93, 5],\n",
       " [30, 93, 5, 94],\n",
       " [93, 5, 94, 14],\n",
       " [5, 94, 14, 20],\n",
       " [94, 14, 20, 29],\n",
       " [14, 20, 29, 95],\n",
       " [20, 29, 95, 24],\n",
       " [29, 95, 24, 96],\n",
       " [95, 24, 96, 97],\n",
       " [24, 96, 97, 21],\n",
       " [96, 97, 21, 39],\n",
       " [97, 21, 39, 24],\n",
       " [21, 39, 24, 98],\n",
       " [39, 24, 98, 99],\n",
       " [24, 98, 99, 14],\n",
       " [98, 99, 14, 26],\n",
       " [99, 14, 26, 100],\n",
       " [14, 26, 100, 101],\n",
       " [26, 100, 101, 21],\n",
       " [100, 101, 21, 102],\n",
       " [101, 21, 102, 14],\n",
       " [21, 102, 14, 20],\n",
       " [102, 14, 20, 36],\n",
       " [14, 20, 36, 103],\n",
       " [20, 36, 103, 104],\n",
       " [36, 103, 104, 31],\n",
       " [103, 104, 31, 105],\n",
       " [104, 31, 105, 21],\n",
       " [31, 105, 21, 106],\n",
       " [105, 21, 106, 107],\n",
       " [21, 106, 107, 14],\n",
       " [106, 107, 14, 108],\n",
       " [107, 14, 108, 24],\n",
       " [14, 108, 24, 40],\n",
       " [108, 24, 40, 14],\n",
       " [24, 40, 14, 20],\n",
       " [40, 14, 20, 41],\n",
       " [14, 20, 41, 109],\n",
       " [20, 41, 109, 42],\n",
       " [41, 109, 42, 44],\n",
       " [109, 42, 44, 110],\n",
       " [42, 44, 110, 111],\n",
       " [44, 110, 111, 43],\n",
       " [110, 111, 43, 14],\n",
       " [111, 43, 14, 37]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dependent and independent variable\n",
    "\n",
    "x=[]\n",
    "y=[]\n",
    "for i in range(len(sequences)):\n",
    "    x.append(sequences[i][0:3])\n",
    "    y.append(sequences[i][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert list to an array\n",
    "x=np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 20, 29])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 20, 29])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([5,20,29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[47,\n",
       " 48,\n",
       " 36,\n",
       " 14,\n",
       " 37,\n",
       " 38,\n",
       " 5,\n",
       " 26,\n",
       " 39,\n",
       " 49,\n",
       " 30,\n",
       " 21,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 14,\n",
       " 58,\n",
       " 59,\n",
       " 21,\n",
       " 31,\n",
       " 60,\n",
       " 30,\n",
       " 61,\n",
       " 62,\n",
       " 31,\n",
       " 29,\n",
       " 63,\n",
       " 24,\n",
       " 64,\n",
       " 14,\n",
       " 26,\n",
       " 38,\n",
       " 14,\n",
       " 26,\n",
       " 65,\n",
       " 66,\n",
       " 14,\n",
       " 20,\n",
       " 24,\n",
       " 40,\n",
       " 32,\n",
       " 41,\n",
       " 67,\n",
       " 68,\n",
       " 33,\n",
       " 6,\n",
       " 69,\n",
       " 70,\n",
       " 42,\n",
       " 71,\n",
       " 72,\n",
       " 24,\n",
       " 33,\n",
       " 73,\n",
       " 74,\n",
       " 33,\n",
       " 75,\n",
       " 76,\n",
       " 35,\n",
       " 14,\n",
       " 20,\n",
       " 77,\n",
       " 78,\n",
       " 14,\n",
       " 79,\n",
       " 80,\n",
       " 21,\n",
       " 81,\n",
       " 32,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 5,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 43,\n",
       " 14,\n",
       " 88,\n",
       " 21,\n",
       " 89,\n",
       " 14,\n",
       " 20,\n",
       " 90,\n",
       " 44,\n",
       " 91,\n",
       " 92,\n",
       " 32,\n",
       " 30,\n",
       " 93,\n",
       " 5,\n",
       " 94,\n",
       " 14,\n",
       " 20,\n",
       " 29,\n",
       " 95,\n",
       " 24,\n",
       " 96,\n",
       " 97,\n",
       " 21,\n",
       " 39,\n",
       " 24,\n",
       " 98,\n",
       " 99,\n",
       " 14,\n",
       " 26,\n",
       " 100,\n",
       " 101,\n",
       " 21,\n",
       " 102,\n",
       " 14,\n",
       " 20,\n",
       " 36,\n",
       " 103,\n",
       " 104,\n",
       " 31,\n",
       " 105,\n",
       " 21,\n",
       " 106,\n",
       " 107,\n",
       " 14,\n",
       " 108,\n",
       " 24,\n",
       " 40,\n",
       " 14,\n",
       " 20,\n",
       " 41,\n",
       " 109,\n",
       " 42,\n",
       " 44,\n",
       " 110,\n",
       " 111,\n",
       " 43,\n",
       " 14,\n",
       " 37]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=to_categorical(y,vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 112)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oVho0JRoyDdT"
   },
   "outputs": [],
   "source": [
    "#import libraries for model building\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense,Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start building model\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add Embedding layer\n",
    "model.add(Embedding(input_dim=vocab_size,output_dim=10,input_length=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add LSTM layer\n",
    "model.add(LSTM(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output layer\n",
    "model.add(Dense(vocab_size,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile \n",
    "model.compile('adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 112 samples, validate on 28 samples\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 2s 18ms/sample - loss: 4.7156 - acc: 0.0536 - val_loss: 4.6970 - val_acc: 0.1429\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 1s 4ms/sample - loss: 4.5158 - acc: 0.0982 - val_loss: 4.8508 - val_acc: 0.1429\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 4.2023 - acc: 0.0982 - val_loss: 5.0494 - val_acc: 0.1429\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 4.0779 - acc: 0.0982 - val_loss: 5.4952 - val_acc: 0.1429\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 3.9984 - acc: 0.0982 - val_loss: 5.5137 - val_acc: 0.1429\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 3.9299 - acc: 0.1071 - val_loss: 5.6663 - val_acc: 0.1429\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 3.8673 - acc: 0.1071 - val_loss: 5.9361 - val_acc: 0.1429\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 3.7993 - acc: 0.1071 - val_loss: 6.4223 - val_acc: 0.1429\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 3.7208 - acc: 0.1071 - val_loss: 6.8295 - val_acc: 0.1429\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 3.6057 - acc: 0.1250 - val_loss: 7.1000 - val_acc: 0.1429\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 3.4923 - acc: 0.1071 - val_loss: 7.0771 - val_acc: 0.1429\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 3.3726 - acc: 0.1161 - val_loss: 7.3313 - val_acc: 0.1786\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 3.2443 - acc: 0.1429 - val_loss: 8.2694 - val_acc: 0.1429\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 1s 7ms/sample - loss: 3.1102 - acc: 0.1518 - val_loss: 7.6357 - val_acc: 0.1071\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 2s 16ms/sample - loss: 2.9643 - acc: 0.1786 - val_loss: 8.1958 - val_acc: 0.1071\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 1s 6ms/sample - loss: 2.7906 - acc: 0.2232 - val_loss: 8.0461 - val_acc: 0.0714\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 2.6118 - acc: 0.2411 - val_loss: 8.4491 - val_acc: 0.0357\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 2.4416 - acc: 0.2768 - val_loss: 8.8895 - val_acc: 0.0714\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 2.2776 - acc: 0.3304 - val_loss: 8.8523 - val_acc: 0.0357\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 1s 6ms/sample - loss: 2.1007 - acc: 0.3929 - val_loss: 9.1394 - val_acc: 0.0357\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 1.9396 - acc: 0.4286 - val_loss: 9.5345 - val_acc: 0.0357\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 1.7726 - acc: 0.5000 - val_loss: 10.0248 - val_acc: 0.0357\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 1s 7ms/sample - loss: 1.6222 - acc: 0.5714 - val_loss: 10.3396 - val_acc: 0.0357\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 1.4900 - acc: 0.6161 - val_loss: 10.3610 - val_acc: 0.0357\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 1s 11ms/sample - loss: 1.3599 - acc: 0.7143 - val_loss: 10.6576 - val_acc: 0.0357\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 1s 6ms/sample - loss: 1.2479 - acc: 0.7232 - val_loss: 11.0070 - val_acc: 0.0357\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 1.1314 - acc: 0.7946 - val_loss: 11.0864 - val_acc: 0.0357\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 1s 10ms/sample - loss: 1.0358 - acc: 0.8304 - val_loss: 11.0428 - val_acc: 0.0357\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 1s 7ms/sample - loss: 0.9448 - acc: 0.8304 - val_loss: 11.0963 - val_acc: 0.0357\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 0.8631 - acc: 0.9107 - val_loss: 11.5517 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 1s 7ms/sample - loss: 0.7872 - acc: 0.8929 - val_loss: 11.3252 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 0.7210 - acc: 0.9464 - val_loss: 11.5467 - val_acc: 0.0357\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 1s 6ms/sample - loss: 0.6720 - acc: 0.9107 - val_loss: 11.5505 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 1s 7ms/sample - loss: 0.6088 - acc: 0.9286 - val_loss: 11.7482 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 1s 8ms/sample - loss: 0.5638 - acc: 0.9196 - val_loss: 11.7787 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 1s 7ms/sample - loss: 0.5183 - acc: 0.9375 - val_loss: 11.7988 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 1s 6ms/sample - loss: 0.4795 - acc: 0.9643 - val_loss: 11.9138 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 1s 7ms/sample - loss: 0.4399 - acc: 0.9554 - val_loss: 12.1498 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 0.4043 - acc: 0.9732 - val_loss: 11.9712 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 0.3733 - acc: 0.9643 - val_loss: 12.0933 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 1s 6ms/sample - loss: 0.3473 - acc: 0.9732 - val_loss: 12.1629 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 0.3241 - acc: 0.9554 - val_loss: 12.2026 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 0.2973 - acc: 0.9821 - val_loss: 12.2087 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 0.2788 - acc: 0.9643 - val_loss: 12.4443 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 1s 6ms/sample - loss: 0.2612 - acc: 0.9911 - val_loss: 12.4315 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 1s 6ms/sample - loss: 0.2367 - acc: 0.9821 - val_loss: 12.4245 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 0.2216 - acc: 0.9732 - val_loss: 12.5741 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 0.2087 - acc: 0.9911 - val_loss: 12.5759 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 0.1910 - acc: 0.9821 - val_loss: 12.6076 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 0.1788 - acc: 0.9911 - val_loss: 12.5987 - val_acc: 0.0357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bfc933cd08>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training model\n",
    "model.fit(x,y,batch_size=1,epochs=50,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5, 20, 29]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([  5,  20,  29]).reshape(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(np.array([  5,  20,  29]).reshape(1,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OovWSOsWyDho"
   },
   "outputs": [],
   "source": [
    "#testing function\n",
    "def predict_next_word(model,tokenizer,text,n_words):\n",
    "    result=''\n",
    "    out_word=[]\n",
    "    \n",
    "    for i in range(n_words):\n",
    "        input_data=text.split()\n",
    "        encoded_data=[tokenizer.texts_to_sequences([x])[0] for x in input_data]\n",
    "        encoded_data=np.array(encoded_data)\n",
    "        encoded_data=encoded_data.reshape(1,3)\n",
    "        \n",
    "\n",
    "        output=np.argmax(model.predict(encoded_data))\n",
    "        \n",
    "        \n",
    "        for index,word in tokenizer.word_index.items():\n",
    "            if word==output:\n",
    "                \n",
    "                out_word.append(index)\n",
    "                text=input_data[1]+\" \"+input_data[2]+\" \"+index\n",
    "    result=' '.join(out_word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'once sleeping in the'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing \n",
    "predict_next_word(model,tokenizer,\"A lion was\",4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickling model to load it in flask server\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickling tokenizer object to use it in flask server later\n",
    "pickle.dump(tokenizer,open(\"tokenizer.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TdMkwBtTyDkq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ROJaSgZbyDnM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NRvt6t6MyDpy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
